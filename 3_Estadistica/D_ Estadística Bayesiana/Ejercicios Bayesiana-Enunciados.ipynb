{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "El objetivo de este cuaderno es complementar la sesión de bayesiana y asentar los conceptos más aplicables:\n",
    "\n",
    "1. Comparación de muestras\n",
    "1. Inferencia de los parámetros de una distribución\n",
    "\n",
    "\n",
    "\n",
    "# Comparación de muestras\n",
    "\n",
    "La comparación de muestras extrae las distribuciones que están debajo de dos o más juegos de datos y compara valores extraídos de estas distribuciones para determinar cuál es \"mejor\".\n",
    "\n",
    "Normalmente empezaríamos la comparación de muestras con el paso de inferencia de la distribución, en este caso supondremos que ya conocemso la distribución que siguen los datos y solo compararemos sus resultados.\n",
    "\n",
    "\n",
    "### Función Auxiliar\n",
    "\n",
    "**¡¡Esta es una función auxiliar, no forma parte del ejercicio, deberíais poder leerla pero no se os pide que la escribáis!!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T20:52:00.033794Z",
     "start_time": "2022-02-18T20:51:59.717303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Esto está para ayudaros, no para que lo escribáis\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [16,8]\n",
    "\n",
    "\n",
    "\n",
    "colores = ['orange', 'lightblue', 'lightgreen', 'green', 'red']\n",
    "\n",
    "def dibujar_muestras(traza, nombres, res=None, datos=None):\n",
    "    plt.figure()\n",
    "    for i,x in enumerate([x for x in nombres if x != 'delta']):\n",
    "        print(f'dibujando histograma para {x}')\n",
    "        sns.histplot(traza.posterior[x].to_series(), color=colores[i])\n",
    "    \n",
    "    if 'delta' in nombres:\n",
    "        plt.figure()\n",
    "        delta = traza.posterior['delta'].to_series()\n",
    "        delta_pos = delta[delta>0]\n",
    "        delta_neg = delta[delta<0]\n",
    "        sns.histplot(delta_neg, color='red')\n",
    "        sns.histplot(delta_pos, color='lightgreen')\n",
    "    \n",
    "    if res:\n",
    "        plt.figure()\n",
    "        sns.histplot(np.concatenate(res['obs_2'])[:len(datos)], color='lightgreen')\n",
    "        sns.histplot(datos, color='orange')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1 comparación de muestras uniformes\n",
    "Este ejercicio es el caso más sencillo de comparación de muestras, vamos a partir de un ejemplo resuelto en el que generamos los datos dentro de PyMC3 para comparar dos muestras uniformes.\n",
    "\n",
    "Tenemos una muestra que varía entre 20 y 30 y otra que varía entre 30 y 40, vamos a obtener valores de ambas y comparar los datos.\n",
    "\n",
    "Para ayudarnos tenemos una función \"dibujar muestras que nos ayuda a ver la forma de las distribuciones en formato Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T15:25:12.519187Z",
     "start_time": "2021-04-23T15:23:53.294560Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "with pm.Model() as model:\n",
    "    dist_1 = pm.Uniform('dist_1', lower=20, upper=30)\n",
    "    dist_2 = pm.Uniform('dist_2', lower=30, upper=40)\n",
    "    \n",
    "    delta = pm.Deterministic('delta', dist_2 - dist_1)\n",
    "    \n",
    "    trace = pm.sample(draws = 10000, return_inferencedata=True)\n",
    "\n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['dist_1', 'dist_2', 'delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:01:28.306968Z",
     "start_time": "2021-03-13T10:01:28.008819Z"
    }
   },
   "source": [
    "## Ejercicio 1 - Comparación de muestras uniformes\n",
    "\n",
    "Partiendo del ejemplo de código anterior, obtén muestras para una distribución uniforme que vaya desde 10 hasta 15 y otra que vaya de 13 a 16.\n",
    "\n",
    "¿Podrías decir que una es mejor que otra fácilmente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T15:23:04.704206Z",
     "start_time": "2021-04-23T15:22:11.357229Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "with pm.Model() as model:\n",
    "    dist_1 = pm.Uniform('dist_1', lower=10, upper=15)\n",
    "    dist_2 = pm.Uniform('dist_2', lower=13, upper=16)\n",
    "    \n",
    "    delta = pm.Deterministic('delta', dist_2-dist_1)\n",
    "    \n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['dist_1', 'dist_2', 'delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T15:31:47.031560Z",
     "start_time": "2021-04-23T15:31:47.002045Z"
    }
   },
   "outputs": [],
   "source": [
    "[trace.posterior['delta'].to_series().min(), trace.posterior['delta'].to_series().max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:15:09.645643Z",
     "start_time": "2021-03-13T10:15:09.317615Z"
    }
   },
   "outputs": [],
   "source": [
    "dibujar_muestras(trace, ['dist_1', 'dist_2', 'delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2 - Comparación de muestras de diferentes distribuciones\n",
    "\n",
    "Podemos utilizar el mismo método para comparar muestras que provienen de diferentes distribuciones.\n",
    "\n",
    "Ojo!, si tenemos un mismo proceso en el que hacemos cambios, la distribución normalmente será la misma, cuando comparamos distribuciones diferenes estamos haciendo algo muy diferente.\n",
    "\n",
    "Un ejemplo de comparación de muestras que provienen de diferentes distribuciones puede ser comparar las visitas a página web que conseguimos desde una campaña de publicidad a través de influencers en instagram con la que hacemos a través de Google Adwords, en estos casos no está garantizado que ambas tengan la misma distribución de probabilidad subyacente.\n",
    "\n",
    "\n",
    "Fijaos que la distribución normal acepta **DOS PARÁMETROS** pero no siguen el mismo criterio que la uniforme, en la uniforme le establecemos un límite inferior y superior, en la normal damos media y desviación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T15:33:12.421321Z",
     "start_time": "2021-04-23T15:32:09.103846Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "with pm.Model() as model:\n",
    "    dist_1 = pm.Uniform('dist_1', lower=5, upper=15)\n",
    "    dist_2 = pm.Normal('dist_2', mu=10, sigma=3)\n",
    "    \n",
    "    delta = pm.Deterministic('delta', dist_2 - dist_1)\n",
    "    \n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['dist_1', 'dist_2', 'delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Compara una muestra normal con una muestra uniforme\n",
    "\n",
    "Repite el ejercicio anterior para generar una muestra normal y una uniforme, queremos que la muestra normal sea claramente superior a la uniforme, prueba algunos parámetros para conseguir ese objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "with pm.Model() as model:\n",
    "    dist_1 = pm.Uniform('dist_1', 5,15 )\n",
    "    dist_2 = pm.Normal('dist_2', 15, 2)\n",
    "    \n",
    "    delta = pm.Deterministic('delta', dist_2 - dist_1)\n",
    "    \n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['dist_1', 'dist_2', 'delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Distribución de Poisson vs uniforme\n",
    "\n",
    "Cambia el ejercicio anterior para que, en lugar de utilizar una distribución normal utilice una de poisson.\n",
    "\n",
    "**Ojo!, la distribución de Poisson acepta un único parámetro**\n",
    "\n",
    "¿Has tenido que hacer transformaciones en los datos para llegar a alguna conclusión?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "with pm.Model() as model:\n",
    "    dist_1 = pm.Uniform('dist_1', lower=5, upper=15)\n",
    "    dist_2 = pm.Poisson('dist_2',10)\n",
    "    \n",
    "    delta = pm.Deterministic('delta', dist_2 - dist_1)\n",
    "    \n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['dist_1', 'dist_2', 'delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectar parámetros de una distribución\n",
    "\n",
    "Para estos ejercicios partiremos de distribuciones que iremos generando a mano y trataremos de comprobar si el ajuste que hace PyMC3 es bueno.\n",
    "\n",
    "## Ejemplo 3 - Obtener parámetros de una distribución uniforme\n",
    "\n",
    "Para determinar los parámetros de una distribución necesitamos dos cosas, por una parte la distribución que creemos que siguen los datos y, por otra, un generador de números aleatorios que vaya probando valores.\n",
    "\n",
    "Nosotros partimos con ventaja, sabemos que vamos a generar una distribución de datos con un generador uniforme entre 0 y 10.\n",
    "\n",
    "Por lo tanto, le vamos a pedir a PyMC3 que detecte los parámetros para un generador uniforme.\n",
    "\n",
    "Tenemos que decirle a PyMC3 cómo puede generar valores que probar en la distribución.\n",
    "\n",
    "Esto son los parámetros **p_A** y **p_B**. Fijáos como los utilizamos más abajo.\n",
    "1. p_A se va a mover entre -5 y 5\n",
    "2. p_B se va a mover entre 5 y 15\n",
    "\n",
    "Por qué esos valores? podríamos obtenerlos de un histograma, nos interesa dejar cierto margen de beneficio y no ir directos al mínimo y al máximo de la distribución para que \"la magia bayesiana\" pueda trabajar mejor con la incertidumbre, de esta forma sabremos no sólo si los parámetros originales están entre 0 y 10 sino también, la probabilidad de que hayan sido, por ejemplo, -1 y 11.\n",
    "\n",
    "Fijaos también en el uso de **pm.sample_posterior_predictive** esa parte lo que hace es extraer muestras del resultado de nuestra inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T20:52:39.864489Z",
     "start_time": "2022-02-18T20:52:06.471783Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "# Obtenemos 1000 medidas de una distribución uniforme entre 0 y 10\n",
    "datos = np.random.uniform(10, 20, 1000)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    p_A = pm.Uniform('p_A', lower=5, upper=15)\n",
    "    p_B = pm.Uniform('p_B', lower=15, upper=25)\n",
    "    \n",
    "    obs = pm.Uniform('obs', lower=p_A, upper=p_B, observed=datos)\n",
    "    \n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "    res = pm.sample_posterior_predictive(trace, samples=1000)\n",
    "        \n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['p_A', 'p_B'], res, datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 4 - Qué pasa si ajustamos a una normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T16:01:42.730590Z",
     "start_time": "2021-04-23T16:00:37.320594Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "# Obtenemos 1000 medidas de una distribución uniforme entre 0 y 10\n",
    "datos = np.random.uniform(10, 20, 1000)\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Como se trata de ajustar a una normal vamos a probar con media entre 10 y 20  y desviación entre 0 y 5\n",
    "    p_A = pm.Uniform('p_A', lower=10, upper=20)\n",
    "    p_B = pm.Uniform('p_B', lower=0, upper=5)\n",
    "    \n",
    "    obs = pm.Normal('obs', p_A, p_B, observed=datos)\n",
    "    \n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "    res = pm.sample_posterior_predictive(trace, samples=1000)\n",
    "        \n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['p_A', 'p_B'], res, datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso vemos que las distribuciones no se parecen en nada si comparamos la original (en naranja) con la resultante (en verde), más allá de la altura de las dos distribuciones (que lo determina el número de observaciones), lo que está mal es la forma en sí misma.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - Ajuste a una normal\n",
    "\n",
    "Ahora vamos a realizar el ajuste de una distribución normal a una normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T16:13:08.846272Z",
     "start_time": "2021-04-23T16:12:17.165189Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "# Obtenemos 1000 medidas de una distribución uniforme entre 0 y 10\n",
    "datos = np.random.normal(20, 3, 1000)\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Como se trata de ajustar a una normal vamos a probar con media entre 10 y 20  y desviación entre 0 y 5\n",
    "    p_A = pm.Uniform('p_A', lower=15, upper=25)\n",
    "    p_B = pm.Uniform('p_B', lower=0, upper=5)\n",
    "    \n",
    "    obs = pm.Normal('obs', p_A, p_B, observed=datos)\n",
    "    \n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "    res = pm.sample_posterior_predictive(trace, samples=1000)\n",
    "        \n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['p_A', 'p_B'], res, datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T16:13:28.889097Z",
     "start_time": "2021-04-23T16:13:28.291651Z"
    }
   },
   "outputs": [],
   "source": [
    "dibujar_muestras(trace, ['p_x', 'p_y'], res, datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 - Ajuste a una distribución Gamma\n",
    "\n",
    "Mismo ejercicio pero ajustando a una distribución Gamma.\n",
    "\n",
    "Recordad que Gamma también tiene dos parámetros, k, que indica cómo de centrada está la distribución en el eje x y \"zeta\", que indica cómo de picuda es la distribución.\n",
    "\n",
    "Probad con algunos valores para las distribuciones uniformes hasta que consideréis que se ha ajustado \"bien\" la distribución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:01:09.523790Z",
     "start_time": "2021-03-13T11:00:47.932240Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "# Obtenemos 1000 medidas de una distribución uniforme entre 0 y 10\n",
    "datos = np.random.normal(20, 3, 5000)\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Como se trata de ajustar a una normal vamos a probar con media entre 10 y 20  y desviación entre 0 y 5\n",
    "    p_A = pm.Uniform('p_A', lower=, upper=)\n",
    "    p_B = pm.Uniform('p_B', lower=, upper=)\n",
    "    \n",
    "    obs = pm.Gamma('obs', p_A, p_B, observed=datos)\n",
    "    \n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "    res = pm.sample_posterior_predictive(trace, samples=1000)\n",
    "        \n",
    "    az.plot_posterior(trace, figsize=(16,8))\n",
    "    \n",
    "dibujar_muestras(trace, ['p_A', 'p_B'], res, datos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
