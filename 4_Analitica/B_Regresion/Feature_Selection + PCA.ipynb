{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc71869e",
   "metadata": {},
   "source": [
    "## Feature Selection \n",
    "\n",
    "https://www.kaggle.com/code/prashant111/comprehensive-guide-on-feature-selection/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ea6d5",
   "metadata": {},
   "source": [
    "#### Filter Methods\n",
    "\n",
    "    Basic methods\n",
    "\n",
    "    Univariate methods\n",
    "\n",
    "    Information gain\n",
    "\n",
    "    Fischer score\n",
    "\n",
    "    Correlation Matrix with Heatmap\n",
    "\n",
    "#### Wrapper Methods\n",
    "\n",
    "    Forward Selection\n",
    "\n",
    "    Backward Elimination\n",
    "\n",
    "    Exhaustive Feature Selection\n",
    "\n",
    "    Recursive Feature Elimination\n",
    "\n",
    "    Recursive Feature Elimination with Cross-Validation\n",
    "\n",
    "#### Embedded Methods\n",
    "\n",
    "\n",
    "    LASSO\n",
    "\n",
    "    RIDGE\n",
    "\n",
    "    Tree Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce14cf7",
   "metadata": {},
   "source": [
    "### 1- Filter Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576f702",
   "metadata": {},
   "source": [
    "**Basic methods**\n",
    "\n",
    "We remove constant/quasi-constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57af233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/Data/CS'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e79a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972e55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35000 entries, 0 to 34999\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(103), int64(268)\n",
      "memory usage: 99.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('./Data/CS/train.csv',nrows=35000)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e92d7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Columns: 370 entries, ID to var38\n",
      "dtypes: float64(99), int64(271)\n",
      "memory usage: 42.3 MB\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('./Data/CS/test.csv', nrows=15000)\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c16f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train[['TARGET']]\n",
    "X_train.drop('TARGET',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3a1474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 370), (15000, 370))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1b2041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.00</td>\n",
       "      <td>195.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>69974</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98642.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>69976</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128930.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>69977</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>69981</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114747.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>69982</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.71</td>\n",
       "      <td>42.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0          1     2     23                 0.0                     0.00   \n",
       "1          3     2     34                 0.0                     0.00   \n",
       "2          4     2     23                 0.0                     0.00   \n",
       "3          8     2     37                 0.0                   195.00   \n",
       "4         10     2     39                 0.0                     0.00   \n",
       "...      ...   ...    ...                 ...                      ...   \n",
       "34995  69974     2     48                 0.0                     0.00   \n",
       "34996  69976     2     65                 0.0                     0.00   \n",
       "34997  69977     2     23                 0.0                     0.00   \n",
       "34998  69981     2     28                 0.0                     0.00   \n",
       "34999  69982     2     23                45.0                    25.71   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "0                         0.00                      0.0   \n",
       "1                         0.00                      0.0   \n",
       "2                         0.00                      0.0   \n",
       "3                       195.00                      0.0   \n",
       "4                         0.00                      0.0   \n",
       "...                        ...                      ...   \n",
       "34995                     0.00                      0.0   \n",
       "34996                     0.00                      0.0   \n",
       "34997                     0.00                      0.0   \n",
       "34998                     0.00                      0.0   \n",
       "34999                    42.27                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "34995                      0.0                      0.0   \n",
       "34996                      0.0                      0.0   \n",
       "34997                      0.0                      0.0   \n",
       "34998                      0.0                      0.0   \n",
       "34999                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  ...  saldo_medio_var29_ult3  \\\n",
       "0                          0.0  ...                     0.0   \n",
       "1                          0.0  ...                     0.0   \n",
       "2                          0.0  ...                     0.0   \n",
       "3                          0.0  ...                     0.0   \n",
       "4                          0.0  ...                     0.0   \n",
       "...                        ...  ...                     ...   \n",
       "34995                      0.0  ...                     0.0   \n",
       "34996                      0.0  ...                     0.0   \n",
       "34997                      0.0  ...                     0.0   \n",
       "34998                      0.0  ...                     0.0   \n",
       "34999                      0.0  ...                     0.0   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "34995                      0.0                      0.0   \n",
       "34996                      0.0                      0.0   \n",
       "34997                      0.0                      0.0   \n",
       "34998                      0.0                      0.0   \n",
       "34999                      0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "0                         0.0                     0.0   \n",
       "1                         0.0                     0.0   \n",
       "2                         0.0                     0.0   \n",
       "3                         0.0                     0.0   \n",
       "4                         0.0                     0.0   \n",
       "...                       ...                     ...   \n",
       "34995                     0.0                     0.0   \n",
       "34996                     0.0                     0.0   \n",
       "34997                     0.0                     0.0   \n",
       "34998                     0.0                     0.0   \n",
       "34999                     0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "34995                      0.0                      0.0   \n",
       "34996                      0.0                      0.0   \n",
       "34997                      0.0                      0.0   \n",
       "34998                      0.0                      0.0   \n",
       "34999                      0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  \n",
       "0                         0.0                     0.0   39205.170000  \n",
       "1                         0.0                     0.0   49278.030000  \n",
       "2                         0.0                     0.0   67333.770000  \n",
       "3                         0.0                     0.0   64007.970000  \n",
       "4                         0.0                     0.0  117310.979016  \n",
       "...                       ...                     ...            ...  \n",
       "34995                     0.0                     0.0   98642.430000  \n",
       "34996                     0.0                     0.0  128930.100000  \n",
       "34997                     0.0                     0.0  117310.979016  \n",
       "34998                     0.0                     0.0  114747.060000  \n",
       "34999                     0.0                     0.0  117310.979016  \n",
       "\n",
       "[35000 rows x 370 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb8b299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sklearn variancethreshold to find constant features\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=0)\n",
    "sel.fit(X_train)\n",
    "\n",
    "sum(sel.get_support()) # get not constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bf83da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# get constant features\n",
    "print(len([x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb402f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = sel.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3df74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21068bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=0.01)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing quasi-constant features\n",
    "\n",
    "sel = VarianceThreshold(threshold=0.01)\n",
    "sel.fit(X_train)  # fit finds the features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ce0f8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sel.get_support())\n",
    "len([x for x in X_train.columns if x not in X_train.columns[sel.get_support()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d3707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.996286\n",
       "1    0.003714\n",
       "Name: ind_var31, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['ind_var31'].value_counts() / np.float(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6215deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then remove the features from training and test set\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5a958",
   "metadata": {},
   "source": [
    "**Univariate selection methods**\n",
    "\n",
    "There are 4 methods that fall under this category :\n",
    "\n",
    "- SelectKBest\n",
    "- SelectPercentile\n",
    "- SelectFpr, SelectFdr, or family wise error SelectFwe\n",
    "- GenericUnivariateSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b106fa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select KBEST\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "718990db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2,k=2).fit_transform(X,y)\n",
    "X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5428455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "X= load_digits()['data']\n",
    "y =load_digits()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94741c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9c6fbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fcbdfe",
   "metadata": {},
   "source": [
    "**Information Gain / Mutual Information**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679616d",
   "metadata": {},
   "source": [
    "**mutual_info_classif**\n",
    "\n",
    "It estimates mutual information for a discrete target variable.\n",
    "\n",
    "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "\n",
    "This function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.\n",
    "\n",
    "It can be used for univariate features selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc330ad",
   "metadata": {},
   "source": [
    "**mutual_info_regression**\n",
    "\n",
    "Estimate mutual information for a continuous target variable.\n",
    "\n",
    "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "\n",
    "The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.\n",
    "\n",
    "It can be used for univariate features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3268e",
   "metadata": {},
   "source": [
    "**Fischer Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d9c17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf924692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 2, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 4, 1, 0],\n",
       "       [5, 4, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 4, 1, 0],\n",
       "       [5, 4, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 2, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [4, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       [7, 3, 4, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [4, 2, 3, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [5, 3, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [5, 3, 4, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [5, 3, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [6, 3, 5, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [6, 2, 5, 1],\n",
       "       [5, 3, 4, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [5, 3, 4, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [5, 3, 4, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [5, 2, 3, 1],\n",
       "       [5, 2, 4, 1],\n",
       "       [6, 3, 6, 2],\n",
       "       [5, 2, 5, 1],\n",
       "       [7, 3, 5, 2],\n",
       "       [6, 2, 5, 1],\n",
       "       [6, 3, 5, 2],\n",
       "       [7, 3, 6, 2],\n",
       "       [4, 2, 4, 1],\n",
       "       [7, 2, 6, 1],\n",
       "       [6, 2, 5, 1],\n",
       "       [7, 3, 6, 2],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 2, 5, 1],\n",
       "       [6, 3, 5, 2],\n",
       "       [5, 2, 5, 2],\n",
       "       [5, 2, 5, 2],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 3, 5, 1],\n",
       "       [7, 3, 6, 2],\n",
       "       [7, 2, 6, 2],\n",
       "       [6, 2, 5, 1],\n",
       "       [6, 3, 5, 2],\n",
       "       [5, 2, 4, 2],\n",
       "       [7, 2, 6, 2],\n",
       "       [6, 2, 4, 1],\n",
       "       [6, 3, 5, 2],\n",
       "       [7, 3, 6, 1],\n",
       "       [6, 2, 4, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [6, 2, 5, 2],\n",
       "       [7, 3, 5, 1],\n",
       "       [7, 2, 6, 1],\n",
       "       [7, 3, 6, 2],\n",
       "       [6, 2, 5, 2],\n",
       "       [6, 2, 5, 1],\n",
       "       [6, 2, 5, 1],\n",
       "       [7, 3, 6, 2],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 3, 5, 1],\n",
       "       [6, 3, 4, 1],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 3, 5, 2],\n",
       "       [5, 2, 5, 1],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 2, 5, 1],\n",
       "       [6, 3, 5, 2],\n",
       "       [6, 3, 5, 2],\n",
       "       [5, 3, 5, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X= iris.data\n",
    "y = iris.target\n",
    "\n",
    "X.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43025ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "X_kbest = chi2_selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42cd43cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e5b32",
   "metadata": {},
   "source": [
    "**Anova F for Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53bc9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif,f_regression\n",
    "\n",
    "X = load_iris().data\n",
    "y = load_iris().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "543191d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fvalue_selector = SelectKBest(f_regression, k=2)\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "184994e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f72ab755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Create features and target\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ba13566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3\n",
      "0    5.1  3.5  1.4  0.2\n",
      "1    4.9  3.0  1.4  0.2\n",
      "2    4.7  3.2  1.3  0.2\n",
      "3    4.6  3.1  1.5  0.2\n",
      "4    5.0  3.6  1.4  0.2\n",
      "..   ...  ...  ...  ...\n",
      "145  6.7  3.0  5.2  2.3\n",
      "146  6.3  2.5  5.0  1.9\n",
      "147  6.5  3.0  5.2  2.0\n",
      "148  6.2  3.4  5.4  2.3\n",
      "149  5.9  3.0  5.1  1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert feature matrix into DataFrame\n",
    "df = pd.DataFrame(X)\n",
    "\n",
    "# View the data frame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d366c942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3\n",
      "0  1.000000 -0.117570  0.871754  0.817941\n",
      "1 -0.117570  1.000000 -0.428440 -0.366126\n",
      "2  0.871754 -0.428440  1.000000  0.962865\n",
      "3  0.817941 -0.366126  0.962865  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f99aa3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAF3CAYAAAAb7WQ5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7Q0lEQVR4nO3dd3wVVfrH8c9D6C20JFSV6ioWEBARFRCpKsWOyoLCgqjYWev6Y1HBLrqogKKyumJHWKWIrljowYJtEWQVKWmUJEgEwj2/P+4YEkggcJPcyeT79jUv78w5d+aZuWGee86cmWvOOURERPysXLQDEBERORQlKxER8T0lKxER8T0lKxER8T0lKxER8T0lKxER8T0lqwAws6Fm9nkE759rZkOKMibJy8w6m9kaM9thZgOO4P1XmNkHxRCaSKmgZFVEzOxyM0v0TkabvQRwRrTj2p+ZjTWzV3Ivc871cc5NL4ZtvWRm9++37Bgzc2ZWvgjWv9DMhke6nhIyDpjknKvunHt3/0Iz+9nMzinozc65fznneh7uRr1j9LuZZZpZhpmtNLM7zKzSYazDmVmLw9324Sqp7UjppGRVBMzsFmAiMB5IAI4CngH6H8G6DjiJF8WJXaLuaOC7I3ljEXz+1zvnagANgFuBy4A5ZmYRrlek5DjnNEUwAbHADuDig9SpRDiZbfKmiUAlr6wrsAG4HUgCXgbGAm8BrwAZwHBvO9OAzcBG4H4gxlvHUODzXNt7EvjVe+9K4ExveW9gN7DHi/lrb/lCYLj3uhxwD/ALkAL8E4j1yo4BHDAEWA+kAXcfZL9fAu7fb9kf6yif69g86q0vGZgMVPHKagPvAanANu91Y6/sAWAv8Lu3L5O85Q64FlgDZAL3Ac2Bxd7xeAOoeKj15zouE4Dl3ntnAXUOsr9/AdYCW4HZQENv+U9ACMjyYq2Uz3t/Bs7J9XkuAp4Atnifdc5nDJhXluLF9Q1wQgEx5Xy2uZYdBewEzvPmTwWWANsJ/31NynWMPvWO6W9e7JcW4rgNBdZ5x/9/wBW5yq4GfvDeNx84uqDtRPvftiZ/TVEPoLRPhBNANt7Jt4A644ClQDwQ55047/PKunrvf4jwibsK4WS1BxhAOHlUAWYCU4Bq3nqWAyO9deScyLz5K4G6QHnC36STgMpe2Vjglf3iyzmheSeTtUAzoDrwDvCyV3aMd0J5zovpZGAXcFwB+/0Sh05WTxA+sdcBagD/BiZ4ZXWBC4GqXtmbwLv5xZ1rmSOcVGoCrb34PvL2Jxb4HhhyGOvfCJzgHfe39z92ueqeTTh5n+J9jv8APs1V/jNeMirg/Tnl3ueZDYz2PsMq5E1WvQh/CalFOHEdBzQoYL0HHCNv+afAQ97rdsBp3raOIZxMbtrvmLbINV/gcfOOUwZwrDffAGjtve5P+G/rOG9b9wCLC9qOJk25p6gHUNon4Aog6RB1fgL65prvBfzsve5KuLVTOVf52P1OdAneSbdKrmWDgI+91zknsgK2vw04Ode6D5asPgKuzVV2LOHE+ceJzJH3W/Ry4LICtvsS4ZbP9lxThreO8t6J9jegea73dAL+V8D62gDb8os71zIHdM41vxK4Pdf8Y8DEw1j/g7nmj/c+q5h83jsNeDjXfHXvuB3jzf/M4SWr9fuV53zGhBPjj4QTTLlD/O0dcIy85a8BzxXwnpuAmfsd0wKTSO7jRjhZbSeczKrsV28uMCzXfDnCLbyjC7MdTWV70jWryG0B6h3iukJDwt1qf/jFW/aHVOfc7/u959dcr48GKgCbzWy7mW0n3MqKz29jZnabmf1gZule3VigXmF2poBYyxNOmH9IyvV6J+ETc0Eedc7V+mMCTspVFkf42/nKXPs1z1uOmVU1sylm9ouZZRBuDdQys5hD7ENyrtdZ+cxXP4z15/4cfiH8OeR3LPMcN+fcDsJ/G40OEWtBfi2owDn3H8JddU8DKWY21cxqHub6GxHursTMWpnZe2aW5B2H8Rzk7+Vgx8059xvhrsJrCP+9vm9mf/LeejTwZK7PeivhLyxHeoykDFGyitwSwq2eAQeps4nwP9Q/HOUt+4PL5z25l/3qbaNerhN/Tedc6/3fZGZnAn8FLgFqewkinfBJoaBtHSrWbPKe8ItKGuHk0TrXfsU65/5IfrcSbtl1dM7VBM7ylhd2Xw7lUOsHaJLr9VGEW0tp+awrz3Ezs2qEu8s2HmFsB90359xTzrl2hFt7rYAxhV2xmTUh3PX3mbfoWeC/QEvvONxF3mOwv4MeN+fcfOdcD8JdgP8l3G0M4b/jkbm/vDjnqjjnFhc2dim7lKwi5JxLB+4FnjazAd63zgpm1sfMHvaqzQDuMbM4M6vn1X+loHXms43NwAfAY2ZW08zKmVlzM+uST/UahJNLKlDezO4lfP3mD8nAMWZW0Gc/A7jZzJqaWXXC37Jfd85lFzbewnLOhQifyJ4ws3gAM2tkZr1y7UsWsN3M6gD/t98qkglfizpSh1o/wJVmdryZVSV87fEt59zefOrNAK4yszbesPDxwDLn3M8RxJcvM+tgZh3NrALhbtTfCQ/gONT7qnp/M7MId9/O8YpqEO6e3eG1gkbt99b9j3OBx83MEsysv5esdxEeLPFHbJOBO82stVc31swuPsh2RHIoWRUB59xjwC2ELxinEv4GeT3wrlflfiARWEV45NYX3rLD8WegIuEBAtsIjxZskE+9+YS70n4k3C31O3m7lN70/r/FzL7I5/0vEB6R+CnhkVy/E77QX1xuJ3zRfanXpfQh4W/tEB41WYVwS2Yp4f3K7UngIjPbZmZPHcG2D7V+CB+Ll/AGqQA35Lci59yHwN8ID8LYTHgE4mVHEFNh1CSc5LcR/oy3AI8cpP4kM8sknAwmejH29r4sANwGXE549N5zwOv7vX8sMN3rvruEgx+3coT/LWwi3M3XBS/5OedmEh5I9Jr3WX8L9DnIdkRymHOR9qSIBJOZLSQ8GOX5aMciUtapZSUiIr6nZCUiIofFzF4wsxQz+7aAcjOzp8xsrZmtMrNTIt2mkpVIAZxzXdUFKJKvlwg/EKEgfYCW3jSC8IjTiChZiYjIYXHOfYp3n14B+gP/dGFLCd+Hl9+AsEJTshIRkaLWiLyjkDcQ4c3fJfI07z1p6zTkMEKD2t0U7RAC4ZW3hkQ7hFLPpadGO4RAqHLONcXy1PuiON9WjGs+knD33R+mOuemRrreSOinJ0REgiSU3z3rh8dLTJEkp43kffpLY478aS6AugFFRILFhSKfIjcb+LM3KvA0IN17Es8RU8tKREQOi5nNIPyLEfXMbAPhR25VAHDOTSb8KK++hJ9OsxO4KtJtKlmJiARJqEhaRgflnBt0iHIHXFeU21SyEhEJEFc03Xi+o2QlIhIkJdCyigYlKxGRIAloy0qjAUVExPfUshIRCZIiuM/Kj5SsRESCJKDdgEpWIiJBEtABFrpmJSIivqeWlYhIgOg+KxER8b+AdgMqWYmIBIlaViIi4nsBHbquARYiIuJ7almJiASJugFFRMT3NMBCRER8Ty0rERHxvYC2rDTAQkREfE8tKxGRAHEumEPXlaxERIJE16xERMT3dM1KREQkOtSyEhEJEnUDioiI7wX02YBKViIiQaKWlYiI+J4GWIiIiESHWlYiIkGibkAREfG9gHYDKlmJiASJkpWIiPidng1YSt0z/nE+XbScOrVr8e4rkw8od84xYeJkPluygsqVK/HA3bdy/LEtAJg1ZwFTpr8GwMghl9G/b48Sjd1vrh77F9p2a8/urF1Mum0i//t23QF1Bo25ki4XdKNabHUGH39pzvLzhven+2U9CGWHyNiaztNjniJtY2pJhh91i77+kYdefo9QKMTArh0Y1q9LnvLNadu5Z8qbZO78nVDIceOlvTizzbG8v+grpr//WU69H39N4rX7r+NPRzcs6V3whUXf/czDby0MH8fOJ3B1z1PzlG/emsHf/jmfzKxdhEKOG/qfwZknNGXJD7/w1KzP2bN3LxViYrh54JmceuxRUdoLOVyHlazMrLxzLru4gikOA/r24PIL+3HXfY/mW/7ZkhWs37CJOa9PY9V3/+W+Rycx47mJpGdk8uyLr/L6tKcAuHTYDXQ94zRia9YoyfB9o223djRo2pDRXUbSsu2xjLh/FHcOGHNAvcQPVzB3+vv8Y2HeLwb/+24dt593C7t/303PK/sw+M6hPHH9IyUVftTtDYUYP302U+64moQ6Nbn83mfo2u5PNG+UkFPnuVkf06vjiVxyzmn8tDGZ6x+ZztyJf+Xczm04t3MbANb8msRNT7xSZhPV3lCICW/8h8mjLyChVg2uePhVupzYnOYN6ubUeW7eMnqe0opLzjqZnzZv4fpn3mXuCcOoXb0KT17Tn/ha1Vm7KY1Rk95hwfgRUdybYhLQbsBCDV03s/Jm9ijwmJmdU8wxFan2bU48aIL5+POl9OvdHTPj5BOOIzNzB6lpW1m0bCWdOrQltmYNYmvWoFOHtixatrIEI/eXDj06svDtjwFY8+VqqtasRq342gfUW/PlaranbDtg+XdLvmH377tz6tRtUK94A/aZb3/aQJOEujSOr0OF8uXpfdpJLFz5wwH1dmTtCv9/5y7iatc8oHzu4q/pfdpJxR6vX337cxJN4mrRuF4tKpSPoVe7Y1m46qc8dQzjN+9vbUfWLuJiqwHwpybxxNeqDkDzBnXZtSeb3XtK1XfvwnGhyCcfOmTLyswMeAqIBeYAt5vZscDzzrldxRxfsUtO3UL9+H0nzoT4eiSnppGcmkb9+Lh9y+PCy8uquvXrsmXTvm67rUlbqJtQN9/EdChnX9qDLxeWrcSfsi2d+nVic+bj68TyzU+/5qkz6oLuXPPQi8z4YAlZu3Yz9c5hB6xn/rJvmHjzlcUer1+lbN9B/dr7vnwm1KrONz8n5alzzbmnMWrSO8z45Cuydu1hyg0XHrCeD79cw3FN4qlYIYBXQspwy6oG0Aa4xjn3L+BRoBVwcTHGJQF15sCuND+xBbOmvBPtUHxn7pJV9DvrFBb84w6eHjOUu599g1CuE8+qtb9SuWIFWjapH8Uo/W9e4mr6dWzNBw/8hUnXDuCe6fMIhVxO+dpNaTw563PuGVSqOonKvEMmK+dcBvAzMNRbtAj4EjjdzAr8V2NmI8ws0cwSn//njCIItXgkxNUlKWVfiyk5JY2EuHokxNUjKWVfSyI5Nby8LOn95748Mmcij8yZyLaUrdRtuK+lWad+XbYkbzms9Z3Y+WQuvP5iHhx+P9m7A9j9chDxtWNJ2pqeM5+yNZ2E/br5Zn6SSK+OJwJwcsuj2LUnm22ZO3PK5y9dRZ9OJ5dMwD4VX6s6Sdsyc+aTt+/I6dr7w8zF39KzXSsATm7WkF17stn+W1a4/rZMbnnu39z35140iatVYnGXqIB2Axb2cUszgTZm1sA5twP4BtgFNCjoDc65qc659s659sP/PKgIQi0eXc84jdnzPsI5x9ff/kD16tWIq1eHzh3bsXj5F6RnZJKekcni5V/QuWO7aIdboub9cw5j+t7EmL43sfyDZXS9sBsALdsey87MnYfVBdi0dTNGTriWB4fdT8aW9EO/IWBaN2vE+qQ0NqRsZU92NvOWrqLLKcflqdOgbi2WfRe+/rJuYwq792RTp2b4eksoFGL+sm/o3ansXq8CaH10fdanbGNjWjp7svcyf+VqupzYLE+dBnVqsuy/6wFYl7SF3dl7qV29Chk7f2f0s+9yY/8zaNu8UTTCLxmhUOTTIZhZbzNbbWZrzeyOfMqPMrOPzexLM1tlZn0j3a3Cdth+DrQn3Lqa4JxbaWZPAm9GGkBxG/N/D7Liy1Vs355B9wFXcu2wwWRnh7/VXzrwXM7q1IHPlqygzyVXU6VyZe6762YAYmvWYOTQQVw2/EYArrnq8jI7EhDgi/8kckq3dkz6dAq7snbxzG1P5ZQ9MmciY/reBMCVdw7lzP5nUalKJaYsfYGPXlvAGxNnMPiuoVSuWoVbn7kdgLRNqTw0/IFo7EpUlI+J4c4h/Rj18IuEQo4BXdrRonECT7+1gNZNG9O13XHcekUfxj0/k1fmLcIwxo28iPAlY1j535+pXyeWxvF1orwn0VU+phx3XHI2o55+h1DI0b9Ta1o0rMcz7y3m+KMS6HpSc2654CzGvbqAf338BWD8fXAvzIzXP/ma9anbmTJnGVPmLANg8ugLqFOjanR3qqgVc8vIzGKAp4EewAZghZnNds59n6vaPcAbzrlnzex4wuMdjolou865Q9cKB3g68CDwD2AF8Dxwl3Nu+aHeuydtXeE2IgUa1O6maIcQCK+8NSTaIZR6Lr1s3R9XXKqcc40Vx3qz5j4V8fm2Sp8bCozNzDoBY51zvbz5OwGccxNy1ZkCrHPOPeTVf8w5d3okMRX6qevOucXABKAPMA94tzCJSkRESpfcYw68KfcNaY2A3ENZN3jLchsLXGlmGwi3qkZHGtNhjdt0zs01sw/DL0vXzcEiImVCEQxdd85NBaZGsIpBwEvOuce8ltXLZnaCc0feR3nYNxk45/Yc6cZERKSYFf9ovo1Ak1zzjb1luQ0DegM455aYWWWgHpBypBvVjy+KiARJ8Y8GXAG0NLOmZlYRuAyYvV+d9UB3ADM7DqgMRHSxM4C3b4uIlGHF3LJyzmWb2fXAfCAGeME5952ZjQMSnXOzgVuB58zsZsABQ11hR/MVQMlKREQOi3NuDuGBE7mX3Zvr9fdA56LcppKViEiQBPTZgEpWIiJB4tPHJUVKyUpEJEgC2rLSaEAREfE9taxERIIkoC0rJSsRkSCJbIS4bylZiYgEiVpWIiLiewFNVhpgISIivqeWlYhIkOg+KxER8b2AdgMqWYmIBIlGA4qIiO8FtGWlARYiIuJ7almJiARJQFtWSlYiIkGi0YAiIuJ3LhTMARa6ZiUiIr6nlpWISJDompWIiPierlmJiIjvBfSalZKViEiQBLQbUAMsRETE99SyEhEJkoC2rJSsRESCRA+yFRER3wtoy0rXrERExPfUshIRCRINXRcREd/TTcEiIuJ7alkduUHtbiqJzQTajJUTox1CIFRpeGa0Qyj1alaqGu0QAmFr5jXFsl6nARYiIiLRoW5AEZEgUTegiIj4ngZYiIiI76llJSIivqcBFiIiItGhZCUiEiQhF/l0CGbW28xWm9laM7ujgDqXmNn3Zvadmb0a6W6pG1BEJEiKeYCFmcUATwM9gA3ACjOb7Zz7PledlsCdQGfn3DYzi490u0pWIiJBUvwDLE4F1jrn1gGY2WtAf+D7XHX+AjztnNsG4JxLiXSj6gYUEZE8zGyEmSXmmkbkKm4E/JprfoO3LLdWQCszW2RmS82sd6QxqWUlIhIgRfG4JefcVGBqBKsoD7QEugKNgU/N7ETn3PZIVigiIkFR/N2AG4EmueYbe8ty2wAsc87tAf5nZj8STl4rjnSj6gYUEQmS4h8NuAJoaWZNzawicBkwe7867xJuVWFm9Qh3C66LZLfUshIRCZJiHg3onMs2s+uB+UAM8IJz7jszGwckOudme2U9zex7YC8wxjm3JZLtKlmJiMhhcc7NAebst+zeXK8dcIs3FQklKxGRINGzAUVExO+ckpWIiPiekpWIiPienrouIiISHWpZiYgEiboBRUTE95SsRETE78K3OAWPrlmJiIjvqWUlIhIk6gYUERHfU7ISERG/0xMsRETE/wKarDTAQkREfE8tKxGRIAnm05aUrEREgkTXrERExP+UrERExPcC2g2oARYiIuJ7almJiASIrlmJiIj/BbQbsEwkq6vH/oW23dqzO2sXk26byP++XXdAnUFjrqTLBd2oFludwcdfmrP8vOH96X5ZD0LZITK2pvP0mKdI25hakuFH3T3jH+fTRcupU7sW774y+YBy5xwTJk7msyUrqFy5Eg/cfSvHH9sCgFlzFjBl+msAjBxyGf379ijR2P3micfH0af32ezMymLYsJv58qtvC6w7850Xadr0KNq07Q7A38eO4fzzexIKOVJT0rh6+M1s3pxcUqH7yoSH/0aPnl3IysriumtuZ9XX3x9Q5813ppFQP47y5cuzZHEiY24ZSygUYtpLE2nRshkAsbE1SE/PpEvnfiW8B8UnqC2rQl+zMjMrzkCKS9tu7WjQtCGju4xk8p1PM+L+UfnWS/xwBXf0v+2A5f/7bh23n3cLt/a+gSVzFjP4zqHFHLH/DOjbg8mP319g+WdLVrB+wybmvD6NsX+9gfsenQRAekYmz774KjOem8iM5yby7Iuvkp6RWVJh+06f3mfTskVT/nT8GYwadTtPT5pQYN0BA/qwY8dveZY9+tiznNKuB+079OT9OR9yz903F3fIvnROzy40b3407ducw803/I3HnhiXb72rh9zIWaf34/RT+1KvXh0GDOwDwLChN9Glcz+6dO7Hv2fP573ZH5Rk+HKECpWszKwcYLlelxodenRk4dsfA7Dmy9VUrVmNWvG1D6i35svVbE/ZdsDy75Z8w+7fd+fUqdugXvEG7EPt25xIbM0aBZZ//PlS+vXujplx8gnHkZm5g9S0rSxatpJOHdoSW7MGsTVr0KlDWxYtW1mCkfvL+ef34uV/vQXAsuVfEFsrlvr14w+oV61aVW6+cQTjJzyZZ3lm5o48dYL6u0WH0vfcc3htxrsAJK74ipq1apCQEHdAvT+OV/ny5alQsUK+x2vAwL68/da/izXeEhcqgsmHDpl4zOwqYAPw9+IPp+jVrV+XLZv2ddttTdpC3YS6R7Susy/twZcLy+7JtiDJqVuoH78viSfE1yM5NY3k1DTqx+87iSTEhZeXVY0a1mfDr5ty5jdu2EyjhvUPqDdu7F95fOIUdu7MOqDsvnG387+fVjBo0EDG/v2RYo3Xrxo0TGDjxs0585s2JtGgYUK+dd+a+QI/rlvKjszfmPXuvDxlnTp3ICUljXU//VKs8ZY0F4p88qODJiszqw70Bx4CzjWzFs65UGFaV2Y2wswSzSxx3Y7S/8dw5sCuND+xBbOmvBPtUCTATj65Nc2aH82sWfPyLf/bvQ/RtHkHZsyYyXXXXlXC0ZU+Fw28muNank6lShU5q0unPGUXXnQe77z1XpQiK0ZlsWXlnNsB3OCcexL4ABjnLT/k7jjnpjrn2jvn2jerfnSRBFtYvf/cl0fmTOSRORPZlrKVug33fbuvU78uW5K3HNb6Tux8MhdefzEPDr+f7N3ZRR1uqZcQV5eklH0tpuSUNBLi6pEQV4+klH2t2uTU8PKyZNQ1Q0hc8QGJKz5gc1IyjZs0zClr1LgBGzcl5al/Wsd2tDvlJNb+uJRPPn6XVi2b8dGCNw9Y76sz3mHgwL7FHr9fDPvLFXyyaDafLJpNclIKjRo1yClr2Kg+mzcVPNBk167dzHn/Q/qc2z1nWUxMDOf168nMt+cUa9zRUCZbVgDOufXey4lACzPrCWBmMcUYV0Tm/XMOY/rexJi+N7H8g2V0vbAbAC3bHsvOzJ35XpsqSNPWzRg54VoeHHY/GVvSiyvkUq3rGacxe95HOOf4+tsfqF69GnH16tC5YzsWL/+C9IxM0jMyWbz8Czp3bBftcEvUs5On075DT9p36Mns2fMZfMVFAHQ89RQy0jNISkrJU3/K1H9y1DHtaNHqNLp0G8CPa9bRvcfFALRo0TSnXr/ze7F69U8ltyNRNu25f+UMinj/vQ+5bNAAANp3aENGeibJyXlH6FarVjXnOlZMTAw9e3VlzY/7RgF37XY6a35cx6b9viyIfxV66LpzLsnMpgF3Ax845/aaWQXn3J7iCy9yX/wnkVO6tWPSp1PYlbWLZ257KqfskTkTGdP3JgCuvHMoZ/Y/i0pVKjFl6Qt89NoC3pg4g8F3DaVy1Src+sztAKRtSuWh4Q9EY1eiZsz/PciKL1exfXsG3QdcybXDBpOdHW5hXjrwXM7q1IHPlqygzyVXU6VyZe67KzxKLbZmDUYOHcRlw28E4JqrLj/oQI2gmzP3I3r3PpvVPyxiZ1YWw4ffklOWuOID2nfoedD3j3/gTlq1ak4oFGL9+o1ce90dxR2yLy2Yv5AePbuw8uuPyMrK4vpR+47DJ4tm06VzP6pWrcK/Xp9MpUoVKVeuHJ99upQXp83IqTfwovN4+80AdgGCb7vxImWFHVFkZuW861VvARsJt8peds4tP9R7Lzq6X9kctlSEZqycGO0QAqFKwzOjHUKpV7NS1WiHEAhbM9cUy+1AqT26RHy+jVvwie9uVSr0MHQvUVUF4oHLgTWFSVQiIlJygnrN6nCfYHEt8AXQwzm3qxjiERGRCPg12UTqcJPV44UZCSgiIlKUDitZKVGJiPic893lpiJRJh5kKyJSVgS1SaFkJSISIC4UzJZVqXoorYiIRJ+Z9Taz1Wa21swKvOHPzC40M2dm7SPdplpWIiIBUtzdgN7Ti54GehB+yPkKM5vtnPt+v3o1gBuBZUWxXbWsREQCxDmLeDqEU4G1zrl1zrndwGuEH3i+v/sIPwT996LYLyUrEZEAKYGbghsBv+aa3+Aty2FmpwBNnHPvF9V+qRtQRCRAimKAhZmNAEbkWjTVOTe1kO8tBzwODI04kFyUrEREJA8vMRWUnDYCTXLNN/aW/aEGcAKw0MwA6gOzzayfcy7xSGNSshIRCZBCPps8EiuAlmbWlHCSuozw82K97bt0IOeH68xsIXBbJIkKlKxERAKluO+zcs5lm9n1wHwgBnjBOfedmY0DEp1zs4tju0pWIiIBUhI3BTvn5gBz9lt2bwF1uxbFNpWsREQCpAS6AaNCQ9dFRMT31LISEQmQoD4bUMlKRCRACvEEilJJyUpEJECC+hMhumYlIiK+p5aViEiAhNQNKCIifqdrViIi4nsaDSgiIr6nm4JFRESiRC0rEZEAUTegiIj4nkYDioiI7wV1NKCuWYmIiO+pZSUiEiBBHQ2oZCUiEiC6ZiUiIr4X1GtWSlYiIgES1G5ADbAQERHfU8tKRCRAdM0qAq+8NaQkNhNoVRqeGe0QAiFr02fRDqHUc1mZ0Q5BDkLXrERExPfUshIREd8L6PgKDbAQERH/U8tKRCRA1A0oIiK+pwEWIiLie6FoB1BMdM1KRER8Ty0rEZEAcagbUEREfC4U0LHrSlYiIgESUstKRET8LqjdgBpgISIivqeWlYhIgAR16LqSlYhIgAS1G1DJSkQkQILastI1KxGRAAkVwXQoZtbbzFab2VozuyOf8lvM7HszW2VmH5nZ0ZHul5KViIgUmpnFAE8DfYDjgUFmdvx+1b4E2jvnTgLeAh6OdLtKViIiAeKwiKdDOBVY65xb55zbDbwG9M8Tg3MfO+d2erNLgcaR7peSlYhIgIQs8snMRphZYq5pRK5NNAJ+zTW/wVtWkGHA3Ej3SwMsREQCpCieYOGcmwpMjXQ9ZnYl0B7oEum6lKxERORwbASa5Jpv7C3Lw8zOAe4GujjndkW6UXUDiogEiCuC6RBWAC3NrKmZVQQuA2bnrmBmbYEpQD/nXEoR7JZaViIiQVLc91k557LN7HpgPhADvOCc+87MxgGJzrnZwCNAdeBNMwNY75zrF8l2laxERAIkZMX/BAvn3Bxgzn7L7s31+pyi3qaSlYhIgAT056x0zUpERPxPLSsRkQAJ6rMBlaxERAIkFMyHritZiYgEiX7WXkREfE8DLERERKJELSsRkQDRNSsREfE9jQYUERHf0zUrERGRKAl8y2rR1z/y0MvvEQqFGNi1A8P65f1Zlc1p27lnyptk7vydUMhx46W9OLPNsby/6Cumv/9ZTr0ff03itfuv409HNyzpXfCNJx4fR5/eZ7MzK4thw27my6++LbDuzHdepGnTo2jTtjsAfx87hvPP70ko5EhNSePq4TezeXNySYXuC/eMf5xPFy2nTu1avPvK5APKnXNMmDiZz5asoHLlSjxw960cf2wLAGbNWcCU6a8BMHLIZfTv26NEY/eTz5d/xUPPvMjeUIgL+nRn+KABeco3Jady76PPsnV7BrE1qjPhztHUj6sLwObkNP7v8ckkpW7BgGfG30mj+vElvxPFKKjXrA6rZWVmMcUVSHHYGwoxfvpsnvnrUGY+fBPzln7NTxvzniCfm/UxvTqeyBsPjOah6y9l/EuzADi3cxveGD+aN8aP5oFRF9MornaZTlR9ep9NyxZN+dPxZzBq1O08PWlCgXUHDOjDjh2/5Vn26GPPckq7HrTv0JP353zIPXffXNwh+86Avj2Y/Pj9BZZ/tmQF6zdsYs7r0xj71xu479FJAKRnZPLsi68y47mJzHhuIs+++CrpGZklFbav7N0b4oF/TOOZ8Xcxa9oTzP14ET/9siFPnUenvMz5Pc7inece5ZrBF/HktFdzyu56aBJDL+nH7BeeYMbTE6hTK7akd6HYhYpg8qNCJSszizGz8cB4Mys1X+m+/WkDTRLq0ji+DhXKl6f3aSexcOUPB9TbkRX+XbAdO3cRV7vmAeVzF39N79NOKvZ4/ez883vx8r/eAmDZ8i+IrRVL/Xy+kVarVpWbbxzB+AlP5lmembkjTx3ngtqzXrD2bU4ktmaNAss//nwp/Xp3x8w4+YTjyMzcQWraVhYtW0mnDm2JrVmD2Jo16NShLYuWrSzByP3jm9VrOaphfZo0TKBChfL06Xo6Hy9akafOul820LHNCQCc2qY1Hy9OBOCnXzawd+9eTm8X/rdctUplqlSuVLI7UALKbLIysy7ASqA2sAZ4wMxOL+7AikLKtnTq19n3zSm+TizJ2zLy1Bl1QXfeX/QVPUY/yHWPvMQdfz7/gPXMX/YNvTuV7WTVqGF9Nvy6KWd+44bNNGpY/4B648b+lccnTmHnzqwDyu4bdzv/+2kFgwYNZOzfHynWeEuj5NQt1I+vlzOfEF+P5NQ0klPTqB8ft295XHh5WZSStpX68XVz5hPi6pK8ZWueOq2aHc2Hny8H4KPPl/Pbziy2p2fy84ZN1KhejZvGPsrFI//KY1NeZu9ev56aj5yzyCc/KkzLKgQ85pwb5Zx7HlgCRPQjWn4yd8kq+p11Cgv+cQdPjxnK3c++QSi07w941dpfqVyxAi2bHHhilrxOPrk1zZofzaxZ8/It/9u9D9G0eQdmzJjJdddeVcLRSVlx28jBJK76notH/pXEVd8TX68O5WLKsXdviC+++YFbRwxmxjMT2LA5mVkfLIx2uFJIhUlWK4E3cl2vWlqY95nZCDNLNLPEaTMXRBLjEYuvHUvS1vSc+ZSt6STs180385NEenU8EYCTWx7Frj3ZbMvcmVM+f+kq+nQ6uWQC9plR1wwhccUHJK74gM1JyTRusu+aXaPGDdi4KSlP/dM6tqPdKSex9selfPLxu7Rq2YyPFrx5wHpfnfEOAwf2Lfb4S5uEuLokpexrMSWnpJEQV4+EuHokpaTuW54aXl4WxderQ1LKlpz55NQtJNStc0CdiWNv480pD3PD1YMAqFm9Ggn16nBsi2No0jCB8jExnN35VL5fs65E4y8JZbYb0Dm30zm3yzm311vUC1hfiPdNdc61d861HzYwOpe5WjdrxPqkNDakbGVPdjbzlq6iyynH5anToG4tln33EwDrNqawe082dWpWAyAUCpXpLsBnJ0+nfYeetO/Qk9mz5zP4iosA6HjqKWSkZ5CUlJKn/pSp/+SoY9rRotVpdOk2gB/XrKN7j4sBaNGiaU69fuf3YvXqn0puR0qJrmecxux5H+Gc4+tvf6B69WrE1atD547tWLz8C9IzMknPyGTx8i/o3LFdtMONihOObc4vGzezYXMKe/ZkM3fhYrqe3j5PnW3pGTm9I8/PmMnA3t2897Ygc8dOtm4PXwpY9tW3ND+6ccnuQAkIarIq9NB1r2XlgARgrresNbDaOZddPOFFpnxMDHcO6ceoh18kFHIM6NKOFo0TePqtBbRu2piu7Y7j1iv6MO75mbwybxGGMW7kRZj3s9Ar//sz9evE0ji+ziG2FHxz5n5E795ns/qHRezMymL48FtyyhJXfED7Dj0P+v7xD9xJq1bNCYVCrF+/kWuvu6O4Q/adMf/3ICu+XMX27Rl0H3Al1w4bTHZ2+J/OpQPP5axOHfhsyQr6XHI1VSpX5r67wiMmY2vWYOTQQVw2/EYArrnq8oMO1Aiy8jEx3DX6aq654wH2hkIM7N2NFsc0YdJLr9O6VXO6nd6eFV9/z5PTXsUw2p10HHePHgZATEw5bh05mOFjxuGc4/hWzbiob5H/+nrUBXXokhV2VJaFz+AVgeeBd4CrgTTgBufcQcfR/r7i7aAevxJTvfMN0Q4hELI2fXboSnJQLqtsDpsvahWbnFwsQxmePOrKiM+3N65/xXfDLArdsnLOOTNrC1wBNAVedM5NK7bIREREPIf7BIsNwN3A4865XcUQj4iIRMCv15widVjJyjm3ASj40QUiIhJVSlYiIuJ7QR0goKeui4iI76llJSISIEF96rqSlYhIgOialYiI+F5Qr1kpWYmIBEgooOlKAyxERMT31LISEQkQXbMSERHfC2YnoJKViEigqGUlIiK+F9T7rDTAQkREfE8tKxGRAAnq0HUlKxGRAAlmqlI3oIhIoISKYDoUM+ttZqvNbK2Z3ZFPeSUze90rX2Zmx0S6X0pWIiJSaGYWAzwN9AGOBwaZ2fH7VRsGbHPOtQCeAB6KdLtKViIiARLCRTwdwqnAWufcOufcbuA1oP9+dfoD073XbwHdzSyicYpKViIiAeKKYDKzEWaWmGsakWsTjYBfc81v8JaRXx3nXDaQDtSNZL80wEJEJECK4qZg59xUYGoRrKrIKFmJiARICQxd3wg0yTXf2FuWX50NZlYeiAW2RLJRdQOKiMjhWAG0NLOmZlYRuAyYvV+d2cAQ7/VFwH+ccxFlUbWsREQCpLjbVc65bDO7HpgPxAAvOOe+M7NxQKJzbjYwDXjZzNYCWwkntIgoWYmIBEhJPMjWOTcHmLPfsntzvf4duLgot6lkJSISIC6gz7BQshIRCZCg/kSIBliIiIjvqWUlIhIgeuq6iIj4XjBTlZKViEigBLVlpWtWIiLie2pZiYgESFBHAypZiYgEiO6zEhER31PLKgIuPbUkNhNoNStVjXYIgeCyMqMdQqlnVWpEOwQ5iKC2rDTAQkREfE/dgCIiAaJuQBER8b1QZD8b5VtKViIiARLMVKVrViIiUgqoZSUiEiBBfdySkpWISIAEdei6kpWISIBoNKCIiPheULsBNcBCRER8Ty0rEZEA0TUrERHxPV2zEhER33N6goWIiPidBliIiIhEiVpWIiIBomtWIiLiexoNKCIivqdrViIiIlGilpWISIBo6LqIiPieBliIiIjvaYCFiIj4ngZYiIiIRIlaViIiARLUARZqWYmIBEgIF/EUCTOrY2YLzGyN9//a+dRpY2ZLzOw7M1tlZpcear1KViIiAeKK4L8I3QF85JxrCXzkze9vJ/Bn51xroDcw0cxqHWyl6gYUEQmQUPS7AfsDXb3X04GFwO25Kzjnfsz1epOZpQBxwPaCVqqWlYiIFKUE59xm73USkHCwymZ2KlAR+Olg9dSyEhEJkKJoV5nZCGBErkVTnXNTc5V/CNTP561354nFOWdmBYZkZg2Al4EhzrmD3s+sZCUiEiBFcZ+Vl5imHqT8nILKzCzZzBo45zZ7ySilgHo1gfeBu51zSw8Vk7oBRUQCJNqjAYHZwBDv9RBg1v4VzKwiMBP4p3PurcKsVMlKRESK0oNADzNbA5zjzWNm7c3sea/OJcBZwFAz+8qb2hxspeoGFBEJkGjfFOyc2wJ0z2d5IjDce/0K8MrhrFfJSkQkQIL6bEAlKxGRANFT10upRd/9zMNvLSQUCjGw8wlc3fPUPOWbt2bwt3/OJzNrF6GQ44b+Z3DmCU1Z8sMvPDXrc/bs3UuFmBhuHngmpx57VJT2wh8mPPw3evTsQlZWFtddczurvv7+gDpvvjONhPpxlC9fniWLExlzy1hCoRDTXppIi5bNAIiNrUF6eiZdOvcr4T2Irs+Xf8VDz7zI3lCIC/p0Z/igAXnKNyWncu+jz7J1ewaxNaoz4c7R1I+rC8Dm5DT+7/HJJKVuwYBnxt9Jo/rxJb8TUXbP+Mf5dNFy6tSuxbuvTD6g3DnHhImT+WzJCipXrsQDd9/K8ce2AGDWnAVMmf4aACOHXEb/vj1KNPaSEu1uwOJyWMnKzCo653YXVzBFbW8oxIQ3/sPk0ReQUKsGVzz8Kl1ObE7zBnVz6jw3bxk9T2nFJWedzE+bt3D9M+8y94Rh1K5ehSev6U98reqs3ZTGqEnvsGD8iINsLdjO6dmF5s2Ppn2bc2jfoQ2PPTGOHmdfdEC9q4fcSGbmDgCmvzKJAQP78M7b7zNs6E05de4bfwcZ6TtKKnRf2Ls3xAP/mMbUh+6hflxdLrvuTrqd3p7mRzfOqfPolJc5v8dZ9O/ZlWVffsuT015lwh2jAbjroUn85YoLOL3dSezM+h0zi9auRNWAvj24/MJ+3HXfo/mWf7ZkBes3bGLO69NY9d1/ue/RScx4biLpGZk8++KrvD7tKQAuHXYDXc84jdiaNUoyfIlAoUYDmlmMmY0H/mFm55lZTDHHVSS+/TmJJnG1aFyvFhXKx9Cr3bEsXJX3JmnD+O33cP7dkbWLuNhqAPypSTzxtaoD0LxBXXbtyWb3nuyS3QEf6XvuObw2410AEld8Rc1aNUhIiDug3h+Jqnz58lSoWCHfb3kDBvbl7bf+Xazx+s03q9dyVMP6NGmYQIUK5enT9XQ+XrQiT511v2ygY5sTADi1TWs+XpwIwE+/bGDv3r2c3u4kAKpWqUyVypVKdgd8on2bEw+aYD7+fCn9enfHzDj5hOPIzNxBatpWFi1bSacObYmtWYPYmjXo1KEti5atLMHIS44Phq4Xi0MmKzM7B1gF1AL+AzwMnFC8YRWNlO07qF973x92Qq3qpGzP+43+mnNP4/0VP9Dz7ue4/pl3ueOSbges58Mv13Bck3gqVgh8r2mBGjRMYOPGzTnzmzYm0aBh/k9ReWvmC/y4bik7Mn9j1rvz8pR16tyBlJQ01v30S7HG6zcpaVupH7+vRZ8QV5fkLVvz1GnV7Gg+/Hw5AB99vpzfdmaxPT2Tnzdsokb1atw09lEuHvlXHpvyMnv3BvXHyyOTnLqF+vH1cuYT4uuRnJpGcmoa9eP3fblKiAsvDyLnXMSTHxWmZfUrcJ1z7lrn3OvAN8Ah285mNsLMEs0scdr7n0UaZ7GZl7iafh1b88EDf2HStQO4Z/o8QqF9H9baTWk8Oetz7hlU4A3bsp+LBl7NcS1Pp1KlipzVpVOesgsvOo933novSpH5220jB5O46nsuHvlXEld9T3y9OpSLKcfevSG++OYHbh0xmBnPTGDD5mRmfbAw2uGKT5XZlpVzbrVzbqGZ1TSzuUAnYLSZnW1mBb7fOTfVOdfeOdd+2LlnFmXMhRZfqzpJ2zJz5pO378jp2vvDzMXf0rNdKwBObtaQXXuy2f5bVrj+tkxuee7f3PfnXjSJq1VicfvFsL9cwSeLZvPJotkkJ6XQqFGDnLKGjeqzeVNyge/dtWs3c97/kD7n7rvdIiYmhvP69WTm23OKNW4/iq9Xh6SULTnzyalbSKhb54A6E8fexptTHuaGqwcBULN6NRLq1eHYFsfQpGEC5WNiOLvzqXy/Zl2Jxl9aJMTVJSllX4spOSWNhLh6JMTVIykldd/y1PDyIPLBT4QUi0I/wcI5lwHMds4dBbwD9AM6FFdgRaH10fVZn7KNjWnp7Mney/yVq+lyYrM8dRrUqcmy/64HYF3SFnZn76V29Spk7Pyd0c++y439z6Bt80bRCD/qpj33L7p07keXzv14/70Pucwbvda+Qxsy0jNJTk7NU79atao517FiYmLo2asra37cd1Lt2u101vy4jk2bkkpsH/zihGOb88vGzWzYnMKePdnMXbiYrqe3z1NnW3oGoVC4e+/5GTMZ2Lub994WZO7YydbtGQAs++rbPAMzZJ+uZ5zG7Hkf4Zzj629/oHr1asTVq0Pnju1YvPwL0jMySc/IZPHyL+jcsV20w5XDUKiLMGZmLuxZAOfc62Z2JYd49Hu0lY8pxx2XnM2op98hFHL079SaFg3r8cx7izn+qAS6ntScWy44i3GvLuBfH38BGH8f3Asz4/VPvmZ96namzFnGlDnLAJg8+gLq1Kga3Z2KkgXzF9KjZxdWfv0RWVlZXD9q3++pfbJoNl0696Nq1Sr86/XJVKpUkXLlyvHZp0t5cdqMnHoDLzqPt98sm12A5WNiuGv01VxzxwPsDYUY2LsbLY5pwqSXXqd1q+Z0O709K77+nienvYphtDvpOO4ePQyAmJhy3DpyMMPHjMM5x/GtmnFR37LZLT3m/x5kxZer2L49g+4DruTaYYPJzg4PfLp04Lmc1akDny1ZQZ9LrqZK5crcd9fNAMTWrMHIoYO4bPiNAFxz1eWBHQnog9+zKhZ2JBfTzKwZMBkY65xbfKj6WR9ODubRK0GNBj4W7RACIen7Qj0zUw7CqgTzJF/SKtRrViz3H7RO6Bjx+fa75GW+uzei0MPbvOtTjYD7CY8GnFyYRCUiIiUnqC2rQicr51zIzHYBS4ARzrldxReWiIjIPod145BzLoVw95+IiPiQX0fzRars3uUqIhJAZb4bUERE/E8tKxER8b2gtqz0s/YiIuJ7almJiASIugFFRMT3nAvmE/mVrEREAsSvT02PlJKViEiA+PX3qCKlARYiIuJ7almJiASIugFFRMT3gtoNqGQlIhIguilYREQkStSyEhEJEN0ULCIivqdrViIi4nsaDSgiIr4X1JaVBliIiIjvqWUlIhIgQR26rmQlIhIgQe0GVLISEQkQDbAQERHfC2rLSgMsRETE95SsREQCJORcxFMkzKyOmS0wszXe/2sfpG5NM9tgZpMOtV4lKxGRAHFF8F+E7gA+cs61BD7y5gtyH/BpYVaqZCUiEiDRblkB/YHp3uvpwID8KplZOyAB+KAwK1WyEhGRPMxshJkl5ppGHMbbE5xzm73XSYQT0v7rLwc8BtxW2JVqNKCISIAUxWhA59xUYGpB5Wb2IVA/n6K791uPM7P8AroWmOOc22BmhYpJyUpEJEBK4idCnHPnFFRmZslm1sA5t9nMGgAp+VTrBJxpZtcC1YGKZrbDOVfg9S0lKxGRAPHBfVazgSHAg97/Z+1fwTl3xR+vzWwo0P5giQp0zUpEJFCccxFPEXoQ6GFma4BzvHnMrL2ZPX+kK1XLSkREioxzbgvQPZ/licDwfJa/BLx0qPUqWYmIBEjUOwGLifmgfzPqzGyEN/pFIqDjWDR0HCOnYxg8umYVdjj3EEjBdByLho5j5HQMA0bJSkREfE/JSkREfE/JKkx920VDx7Fo6DhGTscwYDTAQkREfE8tKxER8b0yn6zMTPeaRcgK+yRKOSgzi4l2DEFgZhWjHYMUvTLbDeglqQeBCsC/nXMfRjmkUsl71D/OuZCZlXPOhaIdU2njJan7gBjgQ+fcgiiHVCrlOo51gX8Dc51ze6MblRSVMtmy8loCTwENgOXA7WZ2nZlVim5kpYuZXQVsAP4e7VhKKzPrAqwEagNrgAfM7PToRlX6mNk5wCqgFvAf4GHghGjGJEWrrHaB1QDaAL2cc5lmlgb0BS4GXolmYKWFmVUn/IugDwFDzGy6c26tWleHLQQ85px7GcDMTgT6AYujGlXp8ytwnXNuIYCZXUD437kERJlsWTnnMoCfgaHeokXAl8DpZpbfD4rJfpxzO4AbnHNPEv5Z6nHeciWqw7MSeCPX9aqllNF/l5Fwzq12zi00s5pmNpfw7yWNNrOz/+iqltKtLH+IM4E23o+E7QC+AXYR7hqUQnDOrfdeTgRamFlP0ECBw+Gc2+mc25Xr2kovYP3B3iMF876IznbOHQW8Q7iV2iG6UUlRKMvJ6nMgDa915ZxbSfiPukoUYyqVnHNJwDS8n7R2zu01swrRjap0MbMYrwWQAMz1lrXWaNXC+2NUqnPuWe//rwPNCR9TKeXKbLJyzm0m/AuWfczsYjM7BvgdyI5qYKWQd51qCpBqZk+a2T+AttGOq5QJER6ZmgacZGb/Bm5DX54Kze03tNnMmgGVCB9TKeXKbLICcM4tBiYAfYB5wLvOueXRjar08YatVwXigcuBNTqOh8c70bYFrgBuJfy3eJVzLjO6kZUuZlbOzJqY2XTgTeBN79+5lHJl9j6r3LwuK+ecU6vqCJnZbUBj4Hbn3K5ox1MamVljYDDwuI7hkTOzeOAC4EUdx+BQspIioSHrIlKclKxERMT3yvQ1KxERKR2UrERExPeUrERExPeUrERExPeUrERExPeUrERExPeUrERExPf+HxZdjVnrj4DdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Correlation Heatmap of Iris Dataset')\n",
    "a = sns.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='black')\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=30)\n",
    "a.set_yticklabels(a.get_yticklabels(), rotation=30)           \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "396b7dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.11757</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.428440</td>\n",
       "      <td>-0.366126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0        1         2         3\n",
       "0 NaN -0.11757  0.871754  0.817941\n",
       "1 NaN      NaN -0.428440 -0.366126\n",
       "2 NaN      NaN       NaN  0.962865\n",
       "3 NaN      NaN       NaN       NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddf980f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "to_drop = [column for column in upper.columns if any(upper[column]>0.9)]\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fb1a5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  5.1  3.5  1.4\n",
       "1  4.9  3.0  1.4\n",
       "2  4.7  3.2  1.3\n",
       "3  4.6  3.1  1.5\n",
       "4  5.0  3.6  1.4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(df.columns[to_drop],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466bff4a",
   "metadata": {},
   "source": [
    "**Wrapper Methods**\n",
    "\n",
    "In wrapper methods, we try to use a subset of features and train a model using them. Based on the inferences that we draw from the previous model, we decide to add or remove features from the subset. The problem is essentially reduced to a search problem. These methods are usually computationally very expensive.\n",
    "\n",
    "Some common examples of wrapper methods are\n",
    "\n",
    "- Forward selection\n",
    "- Backward elimination\n",
    "- Exhaustive feature selection\n",
    "- Recursive feature elimination.\n",
    "- Recursive feature elimination with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "897601b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step forward feature selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1386ce11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./Data/HP/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da4c1f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>...</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>...</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
       "0        1          60         65.0     8450            7            5   \n",
       "1        2          20         80.0     9600            6            8   \n",
       "2        3          60         68.0    11250            7            5   \n",
       "3        4          70         60.0     9550            7            5   \n",
       "4        5          60         84.0    14260            8            5   \n",
       "...    ...         ...          ...      ...          ...          ...   \n",
       "1455  1456          60         62.0     7917            6            5   \n",
       "1456  1457          20         85.0    13175            6            6   \n",
       "1457  1458          70         66.0     9042            7            9   \n",
       "1458  1459          20         68.0     9717            5            6   \n",
       "1459  1460          20         75.0     9937            5            6   \n",
       "\n",
       "      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  \\\n",
       "0          2003          2003       196.0         706  ...           0   \n",
       "1          1976          1976         0.0         978  ...         298   \n",
       "2          2001          2002       162.0         486  ...           0   \n",
       "3          1915          1970         0.0         216  ...           0   \n",
       "4          2000          2000       350.0         655  ...         192   \n",
       "...         ...           ...         ...         ...  ...         ...   \n",
       "1455       1999          2000         0.0           0  ...           0   \n",
       "1456       1978          1988       119.0         790  ...         349   \n",
       "1457       1941          2006         0.0         275  ...           0   \n",
       "1458       1950          1996         0.0          49  ...         366   \n",
       "1459       1965          1965         0.0         830  ...         736   \n",
       "\n",
       "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "0              61              0          0            0         0        0   \n",
       "1               0              0          0            0         0        0   \n",
       "2              42              0          0            0         0        0   \n",
       "3              35            272          0            0         0        0   \n",
       "4              84              0          0            0         0        0   \n",
       "...           ...            ...        ...          ...       ...      ...   \n",
       "1455           40              0          0            0         0        0   \n",
       "1456            0              0          0            0         0        0   \n",
       "1457           60              0          0            0         0     2500   \n",
       "1458            0            112          0            0         0        0   \n",
       "1459           68              0          0            0         0        0   \n",
       "\n",
       "      MoSold  YrSold  SalePrice  \n",
       "0          2    2008     208500  \n",
       "1          5    2007     181500  \n",
       "2          9    2008     223500  \n",
       "3          2    2006     140000  \n",
       "4         12    2008     250000  \n",
       "...      ...     ...        ...  \n",
       "1455       8    2007     175000  \n",
       "1456       2    2010     210000  \n",
       "1457       5    2010     266500  \n",
       "1458       4    2010     142125  \n",
       "1459       6    2008     147500  \n",
       "\n",
       "[1460 rows x 38 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e85c708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 37), (438, 37))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8871553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 33) (438, 33)\n"
     ]
    }
   ],
   "source": [
    "# Removing correlated features\n",
    "threshold = 0.8\n",
    "correlated_columns =[]\n",
    "corr_matrix = data.corr()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i,j])>threshold:\n",
    "            name = corr_matrix.columns[i]\n",
    "            correlated_columns.append(name)\n",
    "            \n",
    "correlated_columns = set(correlated_columns)\n",
    "X_train = X_train.drop(correlated_columns,axis=1)\n",
    "X_test = X_test.drop(correlated_columns,axis=1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c2c66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74517906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01fbc72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   27.1s finished\n",
      "\n",
      "[2023-02-10 20:25:32] Features: 1/10 -- score: 0.6679670690190654[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   27.7s finished\n",
      "\n",
      "[2023-02-10 20:25:59] Features: 2/10 -- score: 0.7213980735040745[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   30.3s finished\n",
      "\n",
      "[2023-02-10 20:26:30] Features: 3/10 -- score: 0.745934938664322[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   29.8s finished\n",
      "\n",
      "[2023-02-10 20:27:00] Features: 4/10 -- score: 0.7639200557604079[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   26.6s finished\n",
      "\n",
      "[2023-02-10 20:27:27] Features: 5/10 -- score: 0.769398166579304[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   32.7s finished\n",
      "\n",
      "[2023-02-10 20:27:59] Features: 6/10 -- score: 0.7764863990945955[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   38.1s finished\n",
      "\n",
      "[2023-02-10 20:28:38] Features: 7/10 -- score: 0.8210846538686165[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   37.9s finished\n",
      "\n",
      "[2023-02-10 20:29:16] Features: 8/10 -- score: 0.8367467429451428[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   40.4s finished\n",
      "\n",
      "[2023-02-10 20:29:56] Features: 9/10 -- score: 0.8518240494737993[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   35.1s finished\n",
      "\n",
      "[2023-02-10 20:30:31] Features: 10/10 -- score: 0.852944227255854"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(cv=3, estimator=RandomForestRegressor(),\n",
       "                          k_features=10, scoring=&#x27;r2&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(cv=3, estimator=RandomForestRegressor(),\n",
       "                          k_features=10, scoring=&#x27;r2&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(cv=3, estimator=RandomForestRegressor(),\n",
       "                          k_features=10, scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1 = SFS(RandomForestRegressor(), \n",
    "           k_features=10, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=3)\n",
    "\n",
    "sfs1.fit(np.array(X_train), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25773183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'BsmtFinSF1',\n",
       " '2ndFlrSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'FullBath',\n",
       " 'GarageCars']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train.columns[list(sfs1.k_feature_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453c6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.8min finished\n",
      "\n",
      "[2023-02-10 20:32:25] Features: 32/10 -- score: 0.8586123222234975[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  1.5min finished\n",
      "\n",
      "[2023-02-10 20:33:58] Features: 31/10 -- score: 0.8589305513270044[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.5min finished\n",
      "\n",
      "[2023-02-10 20:35:28] Features: 30/10 -- score: 0.8640517395970381[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min finished\n",
      "\n",
      "[2023-02-10 20:36:53] Features: 29/10 -- score: 0.8609484407785454[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.7min finished\n",
      "\n",
      "[2023-02-10 20:38:36] Features: 28/10 -- score: 0.8626609593039006[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.5min finished\n",
      "\n",
      "[2023-02-10 20:40:05] Features: 27/10 -- score: 0.8621913086962857[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.4min finished\n",
      "\n",
      "[2023-02-10 20:41:31] Features: 26/10 -- score: 0.8610302095734389[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.3min finished\n",
      "\n",
      "[2023-02-10 20:42:48] Features: 25/10 -- score: 0.8603435381056509[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.3min finished\n",
      "\n",
      "[2023-02-10 20:44:05] Features: 24/10 -- score: 0.8626709457178302[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n"
     ]
    }
   ],
   "source": [
    "# step backward feature elimination\n",
    "\n",
    "sfs1 = SFS(RandomForestRegressor(), \n",
    "           k_features=10, \n",
    "           forward=False, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=3)\n",
    "\n",
    "sfs1 = sfs1.fit(np.array(X_train), y_train)\n",
    "\n",
    "X_train.columns[list(sfs1.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efcaccc",
   "metadata": {},
   "source": [
    "**Embedded Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709ea68",
   "metadata": {},
   "source": [
    "*Lasso Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=100).fit(scaler.transform(X_train.fillna(0)),y_train)\n",
    "lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155378cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = X_train.columns[(lasso.coef_==0)]\n",
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b52989",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = X_train.columns[(lasso.coef_!=0)]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(np.sum(lasso.coef_==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other way\n",
    "\n",
    "sel_ = SelectFromModel(Lasso(alpha=100))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)\n",
    "\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26345ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ab93e",
   "metadata": {},
   "source": [
    "*Random Forests Importance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40466a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/mushrooms.csv')\n",
    "X = df.drop(['class'], axis = 1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, prefix_sep='_')\n",
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2460c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce786ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature vector\n",
    "X2 = StandardScaler().fit_transform(X)\n",
    "len(X2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with n_estimators = 100\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# fit the classifier to the training set\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13223d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32453688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize feature importance\n",
    "plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='w', edgecolor='k')\n",
    "feat = pd.Series(clf.feature_importances_,index=X.columns)\n",
    "feat.nlargest(50).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1983d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class'], axis = 1)\n",
    "y = df['class']\n",
    "X = pd.get_dummies(X, prefix_sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4354b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selec = list(feat[feat>0.01].index)\n",
    "X = StandardScaler().fit_transform(X[selec])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd63dc",
   "metadata": {},
   "source": [
    "## Principal Components Regression // PCA\n",
    "\n",
    "https://towardsdatascience.com/principal-component-regression-clearly-explained-and-implemented-608471530a2f\n",
    "\n",
    "https://analyticsindiamag.com/a-hands-on-guide-to-principal-component-regression-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f81945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv('./Data/winequality-red.csv', sep=';')\n",
    "\n",
    "target = 'quality'\n",
    "X = df.drop(target,axis=1)\n",
    "X = pd.get_dummies(X, prefix_sep='_')\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scale(X_train.fillna(0))\n",
    "X_test_scaled = scale(X_test.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits = 10,shuffle=True,random_state=0 )\n",
    "# Linear Regression\n",
    "lin_reg = LinearRegression().fit(X_train_scaled, y_train)\n",
    "lr_score_train = -1* cross_val_score(lin_reg, X_train_scaled, y_train, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "lr_score_test = mean_squared_error(y_test, lin_reg.predict(X_test_scaled), squared=False)\n",
    "print('Linear Regression Score: {}'.format(lr_score_test))\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_reg = LassoCV().fit(X_train_scaled, y_train)\n",
    "lasso_score_train = -1 * cross_val_score(lasso_reg, X_train_scaled, y_train, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "lasso_score_test = mean_squared_error(y_test, lasso_reg.predict(X_test_scaled), squared=False)\n",
    "print('Lasso Regression Score: {}'.format(lasso_score_test))\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_reg = RidgeCV().fit(X_train_scaled, y_train)\n",
    "ridge_score_train = -1 * cross_val_score(ridge_reg, X_train_scaled, y_train, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "ridge_score_test = mean_squared_error(y_test, ridge_reg.predict(X_test_scaled), squared=False)\n",
    "print('Ridge Regression Score: {}'.format(ridge_score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5dda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_train_pc = pca.fit_transform(X_train_scaled)\n",
    "# View first 5 rows of all principal components\n",
    "pd.DataFrame(pca.components_.T).loc[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164eb3c",
   "metadata": {},
   "source": [
    "The number of principal components (k) to be used in our model is typically determined by\n",
    "cross-validation and visual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c37104",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "rmse_list = []\n",
    "\n",
    "for i in range(1, X_train_pc.shape[1]+1):\n",
    "    rmse_score = -1 * cross_val_score(lin_reg, \n",
    "                                      X_train_pc[:,:i], # Use first k principal components\n",
    "                                      y_train, \n",
    "                                      cv=cv, \n",
    "                                      scoring='neg_root_mean_squared_error').mean()\n",
    "    rmse_list.append(rmse_score)\n",
    "    \n",
    "plt.plot(rmse_list, '-o')\n",
    "plt.xlabel('Number of principal components in regression')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Quality')\n",
    "plt.xlim(xmin=-1);\n",
    "plt.xticks(np.arange(X_train_pc.shape[1]), np.arange(1, X_train_pc.shape[1]+1))\n",
    "plt.axhline(y=lr_score_train, color='g', linestyle='-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85652b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pc_num = 9\n",
    "\n",
    "# Train model with first 9 principal components\n",
    "lin_reg_pc = LinearRegression().fit(X_train_pc[:,:best_pc_num], y_train)\n",
    "\n",
    "# Get cross-validation RMSE (train set)\n",
    "pcr_score_train = -1 * cross_val_score(lin_reg_pc, \n",
    "                                       X_train_pc[:,:best_pc_num], \n",
    "                                       y_train, \n",
    "                                       cv=cv, \n",
    "                                       scoring='neg_root_mean_squared_error').mean()\n",
    "\n",
    "\n",
    "# Get first 9 principal components of test set\n",
    "X_test_pc = pca.transform(X_test_scaled)[:,:best_pc_num]\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = lin_reg_pc.predict(X_test_pc)\n",
    "pcr_score_test_9 = mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with first 7 principal components\n",
    "lin_reg_pc = LinearRegression().fit(X_train_pc[:,:7], y_train)\n",
    "\n",
    "# Get cross-validation RMSE (train set)\n",
    "pcr_score_train = -1 * cross_val_score(lin_reg_pc, \n",
    "                                       X_train_pc[:,:7], \n",
    "                                       y_train, \n",
    "                                       cv=cv, \n",
    "                                       scoring='neg_root_mean_squared_error').mean()\n",
    "\n",
    "\n",
    "# Get first 7 principal components of test set\n",
    "X_test_pc = pca.transform(X_test_scaled)[:,:7]\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = lin_reg_pc.predict(X_test_pc)\n",
    "pcr_score_test_7 = mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ddd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear Regression Score: {}'.format(lr_score_test))\n",
    "print('9_PCA Linear Regression Score: {}'.format(pcr_score_test_9))\n",
    "print('7_PCA Linear Regression Score: {}'.format(pcr_score_test_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE_lr = mean_absolute_error(y_pred = lin_reg.predict(X_test_scaled), y_true = y_test)\n",
    "MAE_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
